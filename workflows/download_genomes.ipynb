{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnjC25eFCPSQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url_da_pesquisa = \"https://www.ebi.ac.uk/metagenomics/api/v1/biomes/root:Environmental:Aquatic:Marine/genomes\"\n",
        "# url_da_pesquisa = \"https://www.ebi.ac.uk/metagenomics/api/v1/genome-catalogues/marine-v2-0/genomes\"\n",
        "\n",
        "def pesquisa_MGnify(max_pages):\n",
        "    \"\"\"\n",
        "    Faz a pesquisa de vários IDs de amostras do MGnify. A pesquisa pode ser feita pelo catálogo de genomas do MGnify ou por bioma.\n",
        "\n",
        "    Parâmetros:\n",
        "    max_pages: número máximo de páginas a buscar.\n",
        "    \"\"\"\n",
        "    lista_ids = []\n",
        "\n",
        "    for page in range(1, max_pages + 1):\n",
        "        url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/biomes/root:Environmental:Aquatic:Marine/genomes?page={page}\"\n",
        "        resposta = requests.get(url)\n",
        "\n",
        "        if resposta.status_code != 200:\n",
        "            print(f\"Erro {resposta.status_code} na página {page}\")\n",
        "            break\n",
        "\n",
        "        dados_json = resposta.json()\n",
        "        ids_atuais = [item[\"id\"] for item in dados_json.get(\"data\", [])]\n",
        "        lista_ids.extend(ids_atuais)\n",
        "\n",
        "        print(f\"Página {page}: {len(ids_atuais)} IDs encontrados\")\n",
        "        time.sleep(1)\n",
        "\n",
        "    with open(\"aquatic_download.json\", \"w\") as i:\n",
        "        json.dump(dados_json, i, indent=4)\n",
        "\n",
        "    with open(\"aquatic_ids.txt\", \"w\") as f:\n",
        "        for id_study in lista_ids:\n",
        "            f.write(id_study + \"\\n\")\n",
        "\n",
        "    print(f\"\\nTotal de {len(lista_ids)} IDs coletados em {page} páginas.\")\n",
        "    return \"aquatic_download.json\", lista_ids"
      ],
      "metadata": {
        "id": "3IbNFbnXClH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arquivo, lista_ids = pesquisa_MGnify(5)"
      ],
      "metadata": {
        "id": "QYlb7abZCpQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lista_ids)"
      ],
      "metadata": {
        "id": "UhjvwZzkCs1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genome_list_url(lista_ids, arquivo_saida=\"links_download_genomes.txt\"):\n",
        "    '''\n",
        "    Faz a pesquisa das urls associadas com cada uma das amostras. Junta todas as urls em um txt único.\n",
        "\n",
        "    Parâmetros:\n",
        "    lista_ids: lista com os IDs das amostras. Ex: 'MGYG000296006'\n",
        "    arquivo_saida: nome do arquivo de saída onde as urls serão salvas. Default: 'links_download_genomes.txt'\n",
        "    '''\n",
        "    lista_download = []\n",
        "    for ids in lista_ids:\n",
        "        print(f\"Baixando links para o ID {ids}\")\n",
        "        url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/genomes/{ids}/downloads\"\n",
        "        resposta =requests.get(url)\n",
        "        print(resposta.status_code)\n",
        "        print(resposta.text[:1000])\n",
        "        if resposta.status_code == 200:\n",
        "            url_ids = [item[\"links\"][\"self\"] for item in resposta.json().get(\"data\", [])]\n",
        "            lista_download.extend(url_ids)\n",
        "        else:\n",
        "            print(\"Erro na requisição.\")\n",
        "    with open(arquivo_saida, \"w\") as f:\n",
        "        for link in lista_download:\n",
        "            f.write(link + \"\\n\")\n",
        "    print (lista_download)\n",
        "    return lista_download"
      ],
      "metadata": {
        "id": "Jr21ZHS9CvYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_links = genome_list_url(lista_ids)"
      ],
      "metadata": {
        "id": "_8BMZXfJCzPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lista_links)"
      ],
      "metadata": {
        "id": "MiVTwkxsC6ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_genome_url(entrada, filtro=\".fna\"):\n",
        "    \"\"\"\n",
        "    Lê um arquivo .txt OU uma lista de links e baixa apenas os arquivos que você quer filtrando pelo tipo de arquivo.\n",
        "\n",
        "    Parâmetros:\n",
        "    entrada: caminho do arquivo .txt contendo os links OU uma lista de links.\n",
        "    filtro: extensão do arquivo a ser baixado. Default: \".fna\"\n",
        "    \"\"\"\n",
        "    if isinstance(entrada, str):\n",
        "        with open(entrada, \"r\") as f:\n",
        "            links = [linha.strip() for linha in f if linha.strip()]\n",
        "    elif isinstance(entrada, list):\n",
        "        links = [linha.strip() for linha in entrada if linha.strip()]\n",
        "    else:\n",
        "        raise TypeError(\"A entrada deve ser um caminho de arquivo (.txt) ou uma lista de links.\")\n",
        "\n",
        "    fna_links = [link for link in links if link.endswith(filtro)]\n",
        "\n",
        "    if not fna_links:\n",
        "        print(f\"Nenhum link com {filtro} encontrado.\")\n",
        "        return\n",
        "\n",
        "    for link in fna_links:\n",
        "        nome_arquivo = link.split(\"/\")[-1]\n",
        "        print(f\"Baixando {nome_arquivo} ...\")\n",
        "\n",
        "        try:\n",
        "            resposta = requests.get(link, timeout=30)\n",
        "            resposta.raise_for_status()\n",
        "            with open(nome_arquivo, \"wb\") as f:\n",
        "                f.write(resposta.content)\n",
        "            print(f\"Download concluído: {nome_arquivo}\")\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Erro ao baixar {nome_arquivo}: {e}\")"
      ],
      "metadata": {
        "id": "nODNshdpC1Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fna_teste = download_genome_url(lista_links)"
      ],
      "metadata": {
        "id": "y-FLOxa4C98D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}